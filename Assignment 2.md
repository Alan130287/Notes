# Assignment 2



---

### 1. 问题说明
设计一个bp神经网络，根据蝴蝶花的特征对其进行分类。
### 2. 数据描述
共有150个数据，每个数据包含蝴蝶花的种类（即标签），共有3个种类，叶长，叶宽，花长和花宽（即特征），单位都是cm。
![image.png-34.6kB][1]

### 3. 网络设计
设计一个单隐层的bp神经网络，输入层有4个节点，对应蝴蝶花的特征数。隐含层的节点数由实验结果得出，其激活函数为对数S形转移函数( Logarithmic sigmoid transfer function )。输出层有3个节点，对应属于某个种类的概率，激活函数为对数S形转移函数。

### 4.算法描述
>1)权值随机赋值，取值范围[-1,+1]
$v_{hi}、w_{i,j}、\tau_i、\phi_j\ (h=1,2,3,4;i=1,2,3,\dots,n;j=1,2,3)$ n为待定的隐含层节点数
2)输入层输入特征，计算隐层活动
$b_i= f(\sum_{h=1}^4a_hw_{hi}+\phi_i)$
$f(x)= \frac{1}{1+e^{-x}}$
3)计算输出层活动
$c_j=f(\sum_{i=1}^nb_iv_{ij}+\tau_j)$
4)网络输出和期望输出相比较，计算出输出层的错误
$d_j=c_j(1-c_j)(c_j^k-c_j)$
5)反传，计算出隐层的误差
$e_i=b_i(1-b_i)\sum_{j=1}^3v_{ij}d_j$ 
6)修改输出层和隐层之间的权值
$\Delta v_{ij}=\alpha b_id_j$
$\Delta v_{ij}(n+1) = \alpha b_id_j + \gamma\Delta v_{ij}(n)$
7)修改隐层和输入层之间的权值
$\Delta W_{hi}= \beta a_he_i$
8)修改偏差
$\Delta \phi_i=\beta e_i$
$\Delta \tau_j=\alpha d_j$
重复2)到8)直到输出层的错误足够小





### 5. 实验细节
1. 训练开始前将数据随机分成训练集和测试集，比例为75%和25%，对应113个训练集数据，37个测试数据。
2. 对数据进行标准化，使其取值在[-1,1]之间。
3. 在每一个epcho，随机抽取一个数据进行训练。

### 6. 实验结果
不同参数对应的实验结果如下：
| Case        | Hidden nodes   | Permitted error | Learning rate($\alpha$,$\beta$) | Momentum rate | Epoch | Accuracy(%) |
| --------   | -----:  | ----:  |:---: || | |
| 1     | 3 |   0.001  |    0.1 0.1    | 0.8  | 1000 | 94.5946 |
| 2     | 3 |   0.001  |    0.1 0.1    | 0.8  | 100 | 97.2973 |
| 3     | 4 |   0.001  |    0.1 0.1    | 0.8  | 48 | 97.2973 |
| 4     | 3 |   0.0005  |    0.1 0.1    | 0.8  | 1000 | 94.5946 |
| 5     | 10 |   0.001  |    0.1 0.1    | 0.8  | 100 | 97.2973 |
| 6     | 4 |   0.001  |    0.01 0.1    | 0.8  | 1000 | 94.5946 |
| 7     | 4 |   0.001  |    0.1 0.01    | 0.8  | 1000 | 91.8919 |
| 8     | 4 |   0.001  |    0.01 0.01    | 0.8  | 1000 | 86.4865 |
| 9     | 4 |   0.001  |    0.1 0.1    | 0  | 1000 | 91.8919 |
| 10     | 4 |   0.001  |    0.1 0.1    | 0.1  | 1000 | 97.2973 |

可在case4中，当隐层节点为4，Permitted error为0.001，学习率都为0.1，动量参数为0.8，模型通过较少训练的时间就可以得到不错的效果，准确率为97.2973%。
对应的模型参数为
W =
    1.3967   -1.6804    2.6691    1.1423
    1.3952   -0.9810    3.0016    1.3445
   -0.7901    1.1701   -0.6529    0.5398
    1.3195   -0.1959   -0.7206    0.1729
    
V =
   -3.7269   -4.1676    5.4849
    4.1898   -6.7739   -3.8352
   -2.3583    6.8805   -9.2389
   -3.3611    2.0537   -1.0181
   
Pi =
    2.0960   -0.3205   -3.8063   -0.7234
    
Tau =
   -0.1072   -0.2576    0.1991
   
模型测试结果如下图所示(注意错误结果位于第26个测试数据)：
![result_best.jpg-23.3kB][2]


### 7. 调用BP工具包实现
调用bp工具包，参数设置与上述最好结果相同，唯一的不同是损失函数改为SSE(The Sum of Squares due to Error)。这是因为工具包里找不到上述的参数设置，代码见附件`bp_with_package.m`。下图为可视化窗口：

![Screenshot from 2018-11-06 15:12:14.png-37.8kB][3]
训练过程的误差如下所示，可见在第70个epoch时，误差已经趋于稳定。
![Screenshot from 2018-11-06 15:14:33.png-13.6kB][4]

准确率为97.297%,与编程实现bp模型相符。


### 8. 体会
1. BP学习算法的基本思想
BP学习算法的基本思想为工作信号正向传播，期间权值不变。误差信号反向传播，期间权值由反馈误差进行调节。通过权值的不断修改，使网络的实际输出更接近期望输出。
2. BP网络设计中节点个数如何确定？
输入层节点和输出层节点可以由数据特征数和类别确定。但是隐层节点较难确定，太少不够精确，太多训练速度变慢，一般为输入层节点数加上输出层节点数-2。
3. 为什么对数据进行通用标准化？
原始的数据可能因为单位不同，分布不同等原因，导致其同数值的变化对模型的影响大大不同。数据标准化主要功能就是消除变量间的量纲关系，使数据具有可比性。从而提高模型的收敛速度和精确性。
4. 为什么要对训练数据的输入顺序进行随机化处理？
对输入顺序进行随机化处理是为了保证能够有监督学习，同时使算法按照梯度下降法则进行学习。假如训练数据是有序的，那么会导致训练结果很难收敛到偏置值。只有保证数据的随机性才能使得BP算法训练结果尽可能地收敛。
5. 为什么训练数据与测试数据要分开？
用训练数据对模型进行模型训练，用测试数据检验模型的训练效果，防止模型过拟合，提高模型的泛化能力。
6. 编程实现与调用工具包实现的不同与感受？
编程实现的过程中，可以对bp神经网络有更深刻的了解，可以知道各个参数的作用，每个步骤的用处。但是对于复杂网络的设计会变得繁琐艰难。调用工具包不需要了解模型的具体细节和原理，便于复杂模型的构建，但是如果不了解实现的原理，模型改进和调试将举步维艰。






  [1]: http://static.zybuluo.com/Counting/pr891hgqqn2wm45qnk96y9bs/image.png
  [2]: http://static.zybuluo.com/Counting/4lit47hi6eepfv8r11w8tujx/result_best.jpg
  [3]: http://static.zybuluo.com/Counting/s9mjxbfswlwf7zgrxabh6h4j/Screenshot%20from%202018-11-06%2015:12:14.png
  [4]: http://static.zybuluo.com/Counting/yecrfpx162d2rn6cqn2l1182/Screenshot%20from%202018-11-06%2015:14:33.png